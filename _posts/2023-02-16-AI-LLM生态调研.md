---
layout: post
title: AI及LLM生态调研
category: AI
catalog: true
published: true
mathjax: true
tags:
  - AI
time: '2023.02.16 10:18:00'
---
> 最近貌似全民都在关注ChatGPT，当前这个领域的生态发展看起来挺快的，对这块没有太多概念，借机学学。

> 所有内容、图片均摘抄自参考文档内容。

# 一、背景介绍
## 神经网络
人脑的神经网络有大概1000亿的神经元，每个神经元大概有1万个关联节点，每个神经元都能够产生电脉冲，最高每秒可达约1000次。神经网络的信号传递和周边的神经元的信息传递有关联。

在原来深度学习的基础上，把神经网络做大，当参数规模做到700亿以上时，出现了智能涌现的现象。但随着模型规模的扩大，性能提升的速率会逐渐减缓。

# 二、LLM架构
## 词向量
### one-hot
### 词袋模型
### 词嵌入(Word Embedding)

## 神经网络

### 前馈神经网络(FFNN)
前馈神经网络是将信息从架构的一端传递到另一端的人工神经网络。前馈神经网络可以执行简单的分类、回归或识别任务，但无法记住之前处理的输入。
![]({{site.baseurl}}/img/2024/Q1/202403271024-FNN.webp)

### 循环神经网络(RNN)
RNN是一种用于处理序列数据的深度学习模型，主要用于语音识别、自然语言处理、时间序列预测等任务。和一般的神经网络来说，它能够处理序列变化的数据。比如：我明天离开杭州 和 我明天来杭州。这两句中的杭州代表的意义是不一样的。如果用前馈神经网络就无法将这个场景区分开。
![]({{site.baseurl}}/img/2024/Q1/202403271036-DNNvsRNN.png)

[参考文档](https://zhuanlan.zhihu.com/p/30844905)
![]({{site.baseurl}}/img/2024/Q1/202403271025-RNN.webp)

另外，RNN有多种类型：
- 一对多：这种RNN类型将一个输入传送到多个输出。它通过使用单个关键字生成句子来支持图片说明文字之类的语言应用程序。
- 多对多：此模型使用多个输入来预测多个输出，适用于处理长度相等的序列数据。例如，你可以使用RNN创建语言翻译器，该翻译器可以分析句子并正确用不同语言组织词句。
- 多对一：多个输入映射到一个输出。这在情绪分析之类的应用程序中非常有用，在情绪分析中，此模型可以根据输入的评价预测客户的正面、负面和中立情绪。

#### 长短时记忆网络(LSTM)
RNN有个问题就是面对长文本预测有长期依赖问题，比如：我的经营业务很广泛，在各个地域都有布局，balabala中间省略一万字，所以我明天要去xx。要推断出xx就需要结合前面的背景介绍，但实际上用RNN就无法有效解决这个问题，所以提出了LSTM网络。  
[参考文档](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

## 卷积网络(CNN)
主要用于图像识别、对象检测等计算机视觉任务。

## Attention
在介绍Attention机制前需要先介绍一下Seq2Seq模型，因为Attention机制是为了解决Encoder-Decoder模型 or Seq2Seq模型存在的问题而提出的。

### Encoder-Decoder模型 or Seq2Seq模型
Seq2Seq模型指的是输入一个序列，然后输出另外一个序列。泛指从Sequence到Sequence的映射问题，并不是一种具体算法(Seq2Seq是应用层面的概念)。主流的Seq2Seq模型都是基于Encoder-Decoder模型来实现的(Encoder-Decoder是网络架构层面的实现)。和RNN相比，Seq2Seq模型最重要的优势在于输入序列和输出序列的长度是可变的。最简单的Seq2Seq模型可以用两个RNN实现，一个RNN作为Encoder，另外一个RNN作为Encoder。Seq2Seq模型适用于需要基于输入的生成式任务，例如翻译、摘要。
![](https://github.com/datawhalechina/learn-nlp-with-transformers/raw/main/docs/%E7%AF%87%E7%AB%A02-Transformer%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86/pictures/1-2-translation.gif)
2014年，Seq2Seq正式提出来后在机器翻译领域表现有意，但该模型还存在一些问题：
- **信息损失**：Encoder和Decoder之间只通过一个固定长度的语义向量C来唯一联系。也就是说，Encoder把输入的整个序列的信息都压缩进一个固定长度的向量中，存在两个弊端：一是语义向量C可能无法完全表示整个序列的信息；二是先输入的信息容易被后输入的信息覆盖掉，输入的序列越长，该现象就越严重；
- **没有侧重点**：我们知道的是每一句话都有其侧重点，那翻译当然也应该注意其侧重点，不应该是每一个词在一个句子中都具有同等地位。
![]({{site.baseurl}}/img/2024/Q1/202403271051-using-RNN-in-translation.png)

Attention机制并不是一个新概念，在很久之前（90年代）就有学者提出，最早应用在图像领域。在机器翻译领域，attention机制的成功应用，取得了巨大成功，几乎是神经网络方法超越传统方法的分水岭。Attention机制可以让神经网络更多的关注到输入中相关的信息，并减少对无关信息的注意。attention本质上是一种实现“注意力”作用的数学建模方法，实现这种功能可以有很多种不同的结构和计算形式，它可以嵌入到Seq2Seq模型中。  

因此在2014-2015年，[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)和[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)提出并改进了注意力Attetion的技术，t通过Attention机制在seq2seq模型中的应用，它极大地提高了机器翻译的质量。Attention注意力使得模型可以根据需要，关注到输入序列的相关部分。 
Attention之所以能有“注意力”这一功能，本质上是由于里面有个softmax，各时序的score通过softmax输出的权重不一样，加权求和后，就有种“注意力”功能了。
![]({{site.baseurl}}/img/2024/Q1/202403271111-attention.webp)
上图例子就是一个计算Attension Score的过程：
1. 计算LSTM2在t=1时刻的输出q1，以及与v1、v2、v3的相似度，即对q1和v1、v2、v3求内积(dot-product)：  
s1=<q1,v1>  
s2=<q1,v2>  
s3=<q1,v3>
2. s1、s2、s3可以理解为未归一化的相似度，通过softmax函数对其归一化，得到a1、a2、a3。满足a1+a2+a3=1。a1、a2、a3就是相似度得分attention score。用于表示解码阶段t=1时刻和编码阶段各个词之间的关系；
例如解码器在第一个时刻，翻译的词是“I”，它和编码阶段的$a_我$这个词关系最近，我的分数最高（比如0.95）。由此达到让输出对输入进行聚焦的能力，找到此时刻解码时最该注意的词，这就是注意力机制。比起循环神经网络有更好的效果。
3. 根据相似度得分对v1、v2、v3进行加权求和，即$h_1=a_1v_1+a_2v_2+a_3v_3$。
4. 向量h1经过softmax函数来预测单词“I”。可以看出，此时的h1由最受关注的向量$v_我$主导，因为$a_我$最高。
下面这个给孩子买玩具的列子个人感觉更容易理解：
![]({{site.baseurl}}/img/2024/Q1/202403271144-choose-toy.webp)
Query(查询/意图)：在这个例子里面就是孩子喜欢玩具的特征：形状、颜色；
Key(索引)：在这个例子里面就是各个玩具的特征：形状、颜色；
Value(值)：在这个例子里面就是家长要考虑玩具的特征：价格、安全；

我们可以将Attention操作计算定义为：$h=Attention(Q, K, V)$。

[参考文档1](https://blog.csdn.net/weixin_42118657/article/details/120077906)  
[参考文档2](https://zhuanlan.zhihu.com/p/402672457)

### Self-Attention
Attention机制能让模型根据需要让解码器关注到输入序列的相关部分，例如：将我爱你翻译为I love you, 翻译前的爱和翻译后的love是有映射关系的。而Self-Attention则是让模型能感知到输入序列内部的关系，无论这些关系的距离有多远，列如：世界上有很多动物，处于顶层食物链中的动物是老虎。这个输入例子中的老虎和第二个动物关联更加密切。此时$h=Attention(Q, K, V)$中的$Q$、$K$和$V$向量指的都是这个输入向量。
这个例子来描述Self-Attention其实挺形象的：去文件柜里面找文件。Query是一个写了文件名的便签，而Key是每个文件柜上的标签，通过Query和Key的乘积来获取Attention分数，而文件柜文件里面的内容就是Value，把Attention分数和文件内容Value进行加权求和得到Self Attention的输出。
![]({{site.baseurl}}/img/2024/Q1/202403271646-self-attention.webp)
另外，翻译这句话：a robot must obey the orders given it中it和a robot的关联更密切，也就意味着Attention分数更高，完整计算Self-Attention的输出过程如下图所示：
![]({{site.baseurl}}/img/2024/Q1/202403271652-self-attention-output.webp)
这几个例子都是关注一个句子中单个单词的Attention计算，如果对句子中的所有单词都做了Attention计算，汇总在一起就是一个矩阵计算。
把所有的输入词向量放到一个矩阵$X$中，然后分别和3个权重矩阵$W^Q$、$W^K$和$W^V$相乘(这三个矩阵是待学习的参数)，得到$Q$,$K$和$V$矩阵，其中$d_k$是Key向量的长度，用softmax进行归一化处理，最终矩阵相乘获得最后的Self-Attention输出。
![]({{site.baseurl}}/img/2024/Q1/202403271711-self-attention-compute.webp)
另外，Self-Attention是词袋模型，对词序不敏感，因此对词序进行调序后重新计算不会影响实际结果。而RNN实际考虑了词序，但也因为输出依赖上一时刻的输入导致只能串行计算。因为语义和词序有一定的关联关系，Self-Attention为了解决这个问题引入两种办法：
- 位置嵌入(Position Embeddings)
- 位置编码(Position Encodings)

[参考文档](https://zhuanlan.zhihu.com/p/402672457)

### Multi-Head Attention
在标准的Attention模型Attention(Q, K, V)中，对Q和K进行相似度匹配,相当于在特定的角度上计算相似度,Q和K所在的向量空间即为观察角度,并且有且仅有一个观察角度。然而，实际情况要复杂得多。
例如,“小明养了一只猫,它特别调皮可爱,他非常喜欢它”。将这句话作为Self-Attention的输入序列,其中每个词都和其他词有一个对应的相似度得分。“猫”从指代的角度看，与“它”的匹配度最高，但从属性的角度看，与“调皮”“可爱”的匹配度最高。由于标准的Attention模型无法处理这种多语义的情况,所以，需要将向量序列Q、K、V多次转换至不同的语义空间，对标准的Attention模型进行多语义匹配改进。(Self-Attention是Attention的特例，所以此种改进方法也适用）。
所以，Attention得分计算公式变成了$head1=Attention(Q_1, K_1, V_1)$，而$Q_1$,$K_1$和$V_1$则是由Attention机制中的$Q$、$K$、$V$矩阵通过和矩阵系数$W_1^Q$、$W_1^K$、$W_1^V$的乘积，将$Q$、$K$、$V$转义到语义空间1中($W_1^Q$、$W_1^K$、$W_1^V$是待学习参数)。
最终的多头注意力模型公式就可以写成：$Multi-Head(Q, K, V)=concat(head_1...head_c)W_O$。因为多头注意力结果串联在一起维度可能比较高，所以通过$W_O$进行一次线性变换，，实现降维和各头信息融合的目的，得到最终结果。

[参考文档](https://zhuanlan.zhihu.com/p/402672457)

## Transformer
虽然自注意力模型有很多优势，但是,要想真正取代循环神经网络，自注意力模型还需要解决如下问题:
1. 在计算自注意力时，没有考虑输入的位置信息，因此无法对序列进行建模;
2. 输入向量X ,同时承担了Q、K、V三种角色,导致其不容易学习;
3. 只考虑了两个输人序列单元之间的关系，无法建模多个输人序列单元之间更复杂的关系;
4. 自注意力计算结果互斥,无法同时关注多个输人
2017年，Google提出了Transformer模型，综合解决了以上问题。Transformer也使用了用Encoder-Decoder框架。为了提高模型能力，每个编码解码块不再是由RNN网络组成，而是由Self Attention+FFNN的结构组成。Transformer最开始提出来解决机器翻译任务，因此可以看作是Seq2Seq模型的一种。
![]({{site.baseurl}}/img/2024/Q1/202403271748-transformer.webp)
[Attention is All You Need](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762)

### Encoder
Encoder由多层编码器组成，每层编码器在结构上都是一样的，但不同层编码器的权重参数是不同的。每层编码器里面，主要由以下两部分组成:
- Self-Attention Layer
- Feed Forward Neural Network

### Decoder
和Encoder类似，不过Decoder中的Self-Attention层用的是Masked Self-Attention，只允许关注到输出序列中早于当前位置之前的单词。实际做法就是将要遮盖的关联分数设置为一个负无穷大的数。

### 训练
#### 损失函数
由于模型的参数都是随机初始化的。模型在每个词输出的概率都是随机的。我们可以把这个概率和正确的输出概率做对比，然后使用反向传播来调整模型的权重，使得输出的概率分布更加接近正确输出。

# 三、大模型
从Transformer发展出来的大模型结构有三种：Encoder-only、Encoder-Decoder和Decoder-only。大模型的演进树可以看下图：
![]({{site.baseurl}}/img/2024/Q1/202403280917-evolutionary-tree.jpg)
[参考文档1](https://zhuanlan.zhihu.com/p/684812895)  
[参考文档2](https://transformers.run/c1/transformer/#transformer-%E5%AE%B6%E6%97%8F)

## Decoder-only
纯Decoder模型只使用Transformer模型中的Decoder模块。在每个阶段，对于给定的词语，注意力层只能访问句子中位于它之前的词语，即只能迭代地基于已经生成的词语来逐个预测后面的词语，因此也被称为自回归(auto-regressive)模型。纯Decoder模型的预训练通常围绕着预测句子中下一个单词展开。纯 Decoder 模型适合处理那些只涉及文本生成的任务。

### [OpenAI GPT](https://github.com/openai)
GPT：generatively pre-trained Transformer。  

#### 初代GPT
在2018年，OpenAI发布最初版本的GPT模型，从 OpenAI 公开的论文（Improving Language Understanding by Generative Pre-Training）可以了解到，这个模型采用了12层的Transformer Decoder结构，用了大约5GB的无监督文本数据进行语言模型任务的训练。虽然**初代GPT模型采用的就已经是生成式的预训练**（这也是 GPT 名字的由来，Generative Pre-Training，即生成式预训练），但使用的是无监督预训练+下游任务微调的范式。

#### GPT-2
在2019年，OpenAI发布了有48层Transformer结构的[GPT-2模型](https://github.com/openai/gpt-2)。在发布的论文(Language Models are Unsupervised Multitask Learners)中，他们发现通过无监督数据配合生成式训练后，GPT展示出了零样本(zero-shot)的多任务能力。

#### GPT-3
在2020年，OpenAI发布了1750亿参数量的GPT-3，一个即便以现在的眼光去看也大得让人惊叹的模型。虽然OpenAI没有明确公开训练这个模型的费用，但大家的估算是当时花了 1200 万美元。同时公开的还有一篇长达60多页的论文(Language Models are Few-Shot Learners)。由于GPT-3没有开源，有些研究员训练出了类似GPT-3的模型：[GPT-Neo](https://zenodo.org/record/5297715)、[GPT-J-6B](https://github.com/kingoflolz/mesh-transformer-jax)。

#### CodeX
在2021年，OpenAI在对GPT-3的研究中还有一个意外的发现，它能够根据一些注释生成很简单的代码。因此在随后的2021年，他们对生成代码这件事情进行了专门的研究投入，并发布了CodeX模型。它可以看作是一个有着代码专精能力的GPT模型，能够根据自然语言输入生成比较复杂的代码。

#### InstructGPT
在2022年，OpenAI 发表了 InstructGPT 的论文(Training language models to follow instructions with human feedback)，从中我们可以一窥解决「一本正经地胡说八道」和「输出有害的内容」这样问题的方法。**InstructGPT 提出了两个阶段的路径来让 GPT 学习人类给出的「优秀范例」，第一阶段是监督学习，第二阶段是强化学习。**
![]({{site.baseurl}}/img/2023/Q2/20230410-GPT.jpg)

#### GPT3.5/ChatGPT
根据分析，GPT-3.5 系列的模型有可能并不是在GPT-3上继续微调而来，而很可能是将代码和自然语言的数据融合在一起，重新从零开始训练了一个基础模型。这个模型可能比 GPT-3 的1750亿参数量更大，它在OpenAI的API中被命名为codex-davinci-002。然后在这个基础模型上，通过指令微调和人类反馈得到了一系列后续的模型，包括ChatGPT。

#### GPT-4
2023年3月，OpenAI公开的一种多模态模型，是对前几个月发布的ChatGPT的多模态升级。GPT-4模型可对图文多模态输入生成应答文字，以及对视觉元素的分类、分析和隐含语义提取，并表现出优秀的应答能力。  
ChatGPT根据输入的指令(prompt)进行回复的能力，是来自于一种被称为指令微调的模型训练方式(prompt tuning)。其实原理很简单，模型依然还是「根据输入的内容，预测下一个token是什么」，只是在指令微调的阶段，输入的内容被换成了这些事先写好的prompt，而prompt后面需要生成的内容，则是事先写好的答案。因此在这一阶段和一开始所说的无监督自回归语言模型训练，最大的不同在于数据。这里的数据，也就是prompt以及对应的回复，都是人写的，换句话说，这一阶段用的是人工标注的数据进行的监督训练。

#### [nanoGPT](https://github.com/karpathy/nanoGPT)
由前特斯拉AI总监、李飞飞徒弟-Andrej Karpathy创建。

#### [GPT-Neo](https://zenodo.org/record/5297715) or [GPT-J-6B](https://github.com/kingoflolz/mesh-transformer-jax)
由于GPT-3没有开源，部分研究人员就训练出了类似GPT-3的大语言模型。

#### [DocsGPT](https://github.com/arc53/DocsGPT)
帮助大家能更加高效的在项目文档中找到价值信息。

### [LLaMA](https://github.com/facebookresearch/llama)
meta开源的ChatGPT模型。

## Encoder-only
纯Encoder模型只使用Transformer模型中的Encoder模块，也被称为自编码(auto-encoding)模型。在每个阶段，注意力层都可以访问到原始输入句子中的所有词语，即具有“双向(Bi-directional)”注意力。  
纯Encoder模型通常通过破坏给定的句子（例如随机遮盖其中的词语），然后让模型进行重构来进行预训练，最适合处理那些需要理解整个句子语义的任务，例如句子分类、命名实体识别（词语分类）、抽取式问答。

### [Bert](https://arxiv.org/abs/1810.04805)
Bert: Bidirectional Encoder Representations from Transformers。
BERT是第一个基于Transformer结构的纯Encoder模型。

## Encoder-Decoder
这个实际就是Seq2Seq模型。

### [ChatGLM](https://chatglm.cn/blog)
模型回答：由清华大学 KEG 实验室与智谱AI共同训练的大型语言模型，名为“ChatGLM”。ChatGLM 是由清华大学 KEG 实验室与智谱AI共同开发而成。  
有两个开源版本：ChatGLM-6B，ChatGLM-130B。

# 预训练模型 
NLP 领域中只有小部分标注过的数据，而有大量的数据是未标注，如何只使用标注数据将会大大影响深度学习的性能，所以为了充分利用大量未标注的原始文本数据，需要利用无监督学习来从文本中提取特征，最经典的例子莫过于词嵌入技术。但是词嵌入只能 word-level 级别的任务（同义词等），没法解决句子、句对级别的任务（翻译、推理等）。
为了解决以上问题，作者提出了GPT框架，用一种半监督学习的方法来完成语言理解任务，GPT的训练过程分为两个阶段：无监督Pre-training和有监督Fine-tuning。

[参考文档](https://paddlepedia.readthedocs.io/en/latest/tutorials/pretrain_model/GPT.html#id4)

## 无监督-预训练(Pre-traning)
给定一个未标记的语料库，n个词嵌入位置信息输入到模型中来预测第n+1个词。

## 有监督-微调(Fine-tuning)
通过监督数据来训练模型，并通过反向传播调整模型中的参数。

## 检索生成增强(RAG)
LLM面临的已知问题：
- 在没有答案的情况下提供虚假信息；
- 当用户需要特定的当前响应时，提供过时或通用的信息；
- 从非权威来源创建响应；
- 由于术语混淆，不同的培训来源使用相同的术语来谈论不同的事情，因此会产生不准确的响应。

为了解决这些问题，提出了检索增强生成(RAG)对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库。

[参考文档](https://aws.amazon.com/cn/what-is/retrieval-augmented-generation/)

### 工作原理
RAG引入了一个信息检索组件，该组件利用用户输入首先从新数据源提取信息。用户查询和相关信息都提供给LLM。LLM使用新知识及其训练数据来创建更好的响应。
![]({{site.baseurl}}/img/2024/Q1/202403281047-RAG.jpg)

# 四、周边配套服务
## [Amazon SageMaker](https://catalog.us-east-1.prod.workshops.aws/workshops/1ac668b1-dbd3-4b45-bf0a-5bc36138fcf1/zh-CN)
SageMaker非常明智的把注意力放到**训练模型**和**发布模型**上， 让数据科学家去做要针对的编程工作。

## [Hugging Face](https://huggingface.co/)
Hugging face 起初是一家总部位于纽约的聊天机器人初创服务商，他们本来打算创业做聊天机器人，然后在github上开源了一个Transformers库，虽然聊天机器人业务没搞起来，但是他们的这个库在机器学习社区迅速大火起来。目前已经共享了超100,000个预训练模型，10,000个数据集，变成了机器学习界的github。

## [langchain](https://langchain.readthedocs.io/en/latest/)
把LLM模型进行了封装，方便模块化调用。

## [chatterbot](https://chatterbot.readthedocs.io/)

# 五、参考文档
- [人人都能看懂的LSTM](https://zhuanlan.zhihu.com/p/32085405)
- [NLP中的RNN、Seq2Seq与attention注意力机制](https://zhuanlan.zhihu.com/p/52119092)
- [循环神经网络有哪些类型？](https://aws.amazon.com/cn/what-is/recurrent-neural-network/)
- [十分钟理解Transformer](https://zhuanlan.zhihu.com/p/82312421)
- [Transofrmers快速入门](https://transformers.run/)
- [基于transformers的自然语言处理(NLP)入门](https://github.com/datawhalechina/learn-nlp-with-transformers)
- [ChatGPT的前世今生：OpenAI的技术「执拗」与「豪赌」](https://www.8btc.com/article/6805740)
- [热点解读：大模型的突现能力和ChatGPT引爆的范式转变](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864784&idx=3&sn=fb8ad092ad32623af7ea822652cd14cc&chksm=84e538eeb392b1f8ff40fa10dc2c84b56904fed261ff15f97f36a1023f887807af62ea39bde7&scene=21#wechat_redirect)
- [ChatGPT的各项超能力从哪儿来？万字拆解追溯技术路线图来了！](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864144&idx=4&sn=1270624988d70f44d4059af7ac4ae4e0&chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&scene=21#wechat_redirect)
- [ChatGLM](https://chatglm.cn/blog)
- [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
- [如何看待亚马逊最新发布的 SageMaker？](https://www.zhihu.com/question/263394266)
- [Huggingface 超详细介绍](https://zhuanlan.zhihu.com/p/535100411)
- [李飞飞高徒教你从0到1构建GPT，马斯克点赞](https://zhuanlan.zhihu.com/p/600057039)
- [Let's build GPT: from scratch, in code, spelled out.  29:30](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- [Building a GPT](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing)
- [Mu Li讲AI](https://www.youtube.com/@mu_li)
- [Transformer](https://www.youtube.com/watch?v=ugWDIIOHtPA&list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&index=61)
- [Transformer模型详解（图解最完整版）](https://zhuanlan.zhihu.com/p/338817680)
- [大语言模型集成工具 LangChain](https://zhuanlan.zhihu.com/p/599688026)
- [大模型解惑](https://www.cnblogs.com/pam-sh/p/17852240.html)
- [整理了48个代码大模型分享！涵盖原始、改进、专用、微调4大类](https://zhuanlan.zhihu.com/p/669434367)
- [大模型到底能有多“大”？](https://www.thepaper.cn/newsDetail_forward_26274423)
- [GPT-4大模型硬核解读，看完成半个专家](https://36kr.com/p/2196628560234373)
- [卷积神经网络（CNN）和循环神经网络(RNN)有什么区别](https://docs.pingcode.com/ask/45298.html)
- [Deeplearning.ai深度学习教程中文笔记](https://github.com/fengdu78/deeplearning_ai_books)
- [深度学习：挖掘序列数据的秘密武器——循环神经网络RNN](https://cloud.baidu.com/article/3258752)
- [NLP：Attention和self-attention的区别](https://blog.csdn.net/qq_41413211/article/details/133635805)
- [大语言模型（LLM）的三条技术路线](https://xueqiu.com/6979880213/249596910)
