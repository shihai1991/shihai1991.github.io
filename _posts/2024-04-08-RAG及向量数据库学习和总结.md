---
layout: post
title: RAG及向量数据库学习和总结
category: AI
catalog: true
tags:
  - AI
time: '2024.04.08 19:15:00'
published: false
---

# LLM存在的问题
LLM面临的已知问题：
- 在没有答案的情况下提供虚假信息；
- 当用户需要特定的当前响应时，提供过时或通用的信息；
- 从非权威来源创建响应；
- 由于术语混淆，不同的培训来源使用相同的术语来谈论不同的事情，因此会产生不准确的响应。

为了解决这些问题，Lewis等人在2020年发表了[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)并在文章中提出了检索增强生成(RAG: Retrieval-Augmented Generation)，通过RAG对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库。

[参考文档](https://aws.amazon.com/cn/what-is/retrieval-augmented-generation/)

# 检索增强生成(RAG)工作原理

## 创建外部数据
我们把LLM训练数据集之外的数据称为**外部数据**。这些数据可以有多种形式存在，例如：文件、数据库记录等。此外，我们可以通过**嵌入语言模型**将外部数据转为向量并存放到**向量数据库**中，这个过程就创建了一个LLM可以理解的**外部知识库**。

### 文本嵌入
文本嵌入衡量文本字符串的相关性，嵌入通常用于：搜索(Search)、聚类(Clustering)、推荐(Recommendations)、异常检测(Anomaly Detection)、多样性测量(Diversity Measurement)和分类(Classification)。下图表示向量化的大致过程，其中Object代表一个文本段落。
![]({{site.baseurl}}/img/2024/Q2/202404090957-embedding-model.png)
通过文本向量化就把**语义相似性**转换为向量空间中的**最近邻关系**。
![]({{site.baseurl}}/img/2024/Q2/202404091001-nearest-neighbors.png)

[参考文档](https://openai.xiniushu.com/docs/guides/embeddings#%E4%BB%80%E4%B9%88%E6%98%AF%E5%B5%8C%E5%85%A5)

### 向量数据库
向量数据库管理系统(VDBMS)或简称向量数据库或向量存储是可以存储向量（固定长度的数字列表）以及其他数据项的数据库。向量数据库通常实现一种或多种近似最近邻(ANN) 算法，以便可以使用查询向量搜索数据库以检索最接近匹配的数据库记录。  
在langchain的[vectorstores目录](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/vectorstores)中集成了很多向量数据库。  

[Langchain中集成的向量数据库](https://python.langchain.com/docs/integrations/vectorstores/pgembedding/)

#### Postgres Embedding
Postgres Embedding是Postgres的一个开源向量相似性搜索，使用Hierarchical Navigable Small Worlds(HNSW)进行近似最近邻搜索。

```python
## Loading Environment Variables
from typing import List, Tuple
from langchain.docstore.document import Document
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import PGEmbedding
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter


os.environ["DATABASE_URL"] = getpass.getpass("Database Url:")

# 通过loader加载外部数据
loader = TextLoader("state_of_the_union.txt")
documents = loader.load()
# 对文档进行分块，Document长度过大会导致LLM无法处理
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

# 使用OpenAI API为给定文本生成嵌入
# https://js.langchain.com.cn/docs/modules/models/embeddings/integrations
embeddings = OpenAIEmbeddings()
connection_string = os.environ.get("DATABASE_URL")
collection_name = "state_of_the_union"

# 将知识向量存放入向量数据库中
db = PGEmbedding.from_documents(
    embedding=embeddings,
    documents=docs,
    collection_name=collection_name,
    connection_string=connection_string,
)

# 检索相似的知识内容
query = "What did the president say about Ketanji Brown Jackson"
docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)

# 输出相似知识内容及评分
for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print(doc.page_content)
    print("-" * 80)
```

#### Weaviate
Weaviate是一个开源向量数据库。

```python
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.embeddings.openai import OpenAIEmbeddings
import weaviate
from langchain_weaviate.vectorstores import WeaviateVectorStore

# 加载外部数据源
loader = TextLoader("state_of_the_union.txt")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

# 使用OpenAI API为给定文本生成嵌入
embeddings = OpenAIEmbeddings()

# 连接到Weaviate数据库
weaviate_client = weaviate.connect_to_local()
# 将知识向量存放入向量数据库中
db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)

# 查询相似文档
query = "What did the president say about Ketanji Brown Jackson"
docs = db.similarity_search(query)

# 打印查询结果前100个字符串
for i, doc in enumerate(docs):
    print(f"\nDocument {i+1}:")
    print(doc.page_content[:100] + "...")
```

向量数据库有很多，这里不一一展开陈述，但LangChain都已经做了标准封装，所以操作步骤都很类似，更多的向量数据库使用可以参阅LangChain的[Vector stores](https://python.langchain.com/docs/integrations/vectorstores/)。
![]({{site.baseurl}}/img/2024/Q2/20240409-vector-databases.png)

## 检索相关信息
把用户查询转换为向量并在向量数据库中进行查询，向量数据库中各种`db.similarity_search(query)`就是一个检索查询过程。

## 增强LLM提示
通过RAG检索到的相关数据来增强用户输入，就可以让LLM为用户查询生成准确的答案。

![]({{site.baseurl}}/img/2024/Q1/202403281047-RAG.jpg)

# 参考文档
- [LLM生态调研](https://github.com/shihai1991/shihai1991.github.io/blob/master/_posts/2023-02-16-AI-LLM%E7%94%9F%E6%80%81%E8%B0%83%E7%A0%94.md)
- [AWS RAG](https://aws.amazon.com/cn/what-is/retrieval-augmented-generation/)
- [向量数据库（第 1 部分）：每个数据库有何不同？](https://www.modb.pro/db/1696009523089723392)
- [What are Vector Embeddings](https://www.pinecone.io/learn/vector-embeddings/)
